{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXJs2_F3aD9P"
   },
   "source": [
    "# **Load the dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UM48VP-3wlOL"
   },
   "source": [
    "# **Downloading neccessary module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPQN9qr6wyg-"
   },
   "outputs": [],
   "source": [
    "!pip3 install nltk\n",
    "!pip3 install gensim\n",
    "!pip3 install emoji\n",
    "!pip3 install transformers\n",
    "!pip install scikit-learn\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wj15_ADXw-Mm"
   },
   "outputs": [],
   "source": [
    "# downloading nltk package\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "u8djiiYV4Gkq",
    "outputId": "f5b04028-5465-4dd1-99f2-a4ff9e1de2d2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"EcoPreprocessed.csv\") #load the dataset here\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLvDNPbHSEjC"
   },
   "outputs": [],
   "source": [
    "#random sampling the data for equal proportions of positive negative and neutral\n",
    "import pandas as pd\n",
    "division_groups = df.groupby('division')\n",
    "positive_df = division_groups.get_group('positive').sample(n=700)\n",
    "neutral_df = division_groups.get_group('neutral')\n",
    "negative_df = division_groups.get_group('negative')\n",
    "new_df = pd.concat([positive_df, neutral_df, negative_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QoABQL2vf9bF",
    "outputId": "bf319bc8-3afe-45f2-cc73-b1e4928e0603"
   },
   "outputs": [],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmRWTwd64RH5",
    "outputId": "5815bb13-41a3-4041-e0b8-12d0f5c5d43b"
   },
   "outputs": [],
   "source": [
    "reviewsList_temp =new_df['review'].tolist()\n",
    "label_list =new_df['division'].tolist()\n",
    "reviewsList_temp[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJmb-pxBaY-R"
   },
   "source": [
    "### **Data-preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KKiBtZ-G8SWh",
    "outputId": "2a17996b-7ceb-4cce-f1fd-9ba46a6508d9"
   },
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import strip_numeric\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "import emoji\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zhzN21muXRsb",
    "outputId": "ce719823-8c69-4457-fa06-bb11e4a95929"
   },
   "outputs": [],
   "source": [
    "def check_if_verb(word):\n",
    "    parts = wordnet.synsets(word, pos=wordnet.VERB)\n",
    "    return len(parts) > 0\n",
    "def check_if_noun(word):\n",
    "    parts = wordnet.synsets(word, pos=wordnet.NOUN)\n",
    "    return len(parts) > 0\n",
    "def check_if_adv(word):\n",
    "    parts = wordnet.synsets(word, pos=wordnet.ADV)\n",
    "    return len(parts) > 0\n",
    "def check_if_adj(word):\n",
    "    parts = wordnet.synsets(word, pos=wordnet.ADJ)\n",
    "    return len(parts) > 0\n",
    "def preprocess_reviews(text):\n",
    "    # Remove emojis\n",
    "    processed_text = emoji.demojize(text)\n",
    "    # Remove numeric characters\n",
    "    processed_text = strip_numeric(text)\n",
    "    # Remove non-alphanumeric characters and convert to lowercase\n",
    "    processed_text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text.lower())\n",
    "    # Tokenize the text\n",
    "    token_list = gensim.utils.simple_preprocess(processed_text)\n",
    "    # Remove stop words and non-nouns, verbs, adjectives, and adverbs\n",
    "    stop_words = gensim.parsing.preprocessing.STOPWORDS\n",
    "    token_list = [token for token in token_list if token not in stop_words\n",
    "                  and (check_if_noun(token)\n",
    "                  or check_if_verb(token)\n",
    "                  or check_if_adj(token)\n",
    "                  or check_if_adv(token))]\n",
    "    return token_list\n",
    "\n",
    "reviewsList=[]\n",
    "for i in reviewsList_temp:\n",
    "  string_temp=\"\"\n",
    "  processed_reviews_temp=preprocess_reviews(i)\n",
    "  for j in processed_reviews_temp:\n",
    "    if string_temp==\"\":\n",
    "      string_temp=j\n",
    "      continue\n",
    "    else:\n",
    "      if j==\"\":\n",
    "        break\n",
    "      else:\n",
    "        string_temp=string_temp+\" \"+j\n",
    "  reviewsList.append(string_temp)\n",
    "\n",
    "reviewsList[:5] #preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "MbQhPo62WISi",
    "outputId": "8e260c84-0ea0-4b6a-e952-bf12f3be6a1f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = [\"positive\",\"negative\",\"neutral\"]\n",
    "positive_count=label_list.count(\"positive\")\n",
    "negative_count=label_list.count(\"negative\")\n",
    "neutral_count=label_list.count(\"neutral\")\n",
    "sizes = [positive_count,negative_count,neutral_count]\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "ax.set_title('labels propotions')\n",
    "plt.savefig(\"labels proportions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvE2i3vo8tDh"
   },
   "source": [
    "data splitting into 60/20/20 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQSs5rfS8pMD",
    "outputId": "d26f5560-3913-4c51-b69d-1d61643866df"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "texts_train, texts_test, labels_train, labels_test = train_test_split(reviewsList, label_list, test_size=0.2, random_state=42)\n",
    "texts_train, texts_val, labels_train, labels_val = train_test_split(texts_train, labels_train, test_size=0.25, random_state=42)\n",
    "from tabulate import tabulate\n",
    "table_data = [[\"Label\", \"Training Set\", \"Validation Set\", \"Test Set\"],\n",
    "              [\"Positive\", labels_train.count(\"positive\"), labels_val.count(\"positive\"), labels_test.count(\"positive\")],\n",
    "              [\"Negative\", labels_train.count(\"negative\"), labels_val.count(\"negative\"), labels_test.count(\"negative\")],\n",
    "              [\"Neutral\", labels_train.count(\"neutral\"), labels_val.count(\"neutral\"), labels_test.count(\"neutral\")],\n",
    "              [\"Total\",len(labels_train), len(labels_val), len(labels_test)]]\n",
    "tablefmt = \"fancy_grid\"\n",
    "headers = [\"\\033[34m{}\\033[0m\".format(header) for header in table_data[0]]\n",
    "table_data = [headers] + table_data[1:]\n",
    "colored_data = [[f\"\\033[32m{col}\\033[0m\" if isinstance(col, int) else col for col in row] for row in table_data]\n",
    "print(tabulate(colored_data, headers=\"firstrow\", tablefmt=tablefmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKviaYmL8gqm"
   },
   "source": [
    "### **Q2-kmeans clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXcc0r4k5X8F"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0OoFFMFgR8G",
    "outputId": "bd3b4b58-5c2b-458b-f297-8f3b19658382"
   },
   "outputs": [],
   "source": [
    "# vectorize the text\n",
    "vectorizer = TfidfVectorizer()\n",
    "T = vectorizer.fit_transform(reviewsList)\n",
    "X=T.toarray()\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "class MyKMeans:\n",
    "    def __init__(self, n_clusters=5, max_iter=100):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "    def fit(self, X):\n",
    "        # Step 1: Randomly initialize centroids\n",
    "        self.centroids = self._initialize_centroids_step1(X)\n",
    "        for i in range(self.max_iter):\n",
    "            # Step 2: Assign each point to the closest centroid\n",
    "            self.labels = self._assign_labels_step2(X)\n",
    "            \n",
    "            # Step 3: Update centroids by computing the mean of all points assigned to each cluster\n",
    "            self.centroids = self._update_centroids_step3(X)\n",
    "        \n",
    "        return self.labels, self.centroids\n",
    "    def _initialize_centroids_step1(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        centroids_indices = np.random.choice(n_samples, self.n_clusters, replace=False)\n",
    "        centroids = X[centroids_indices]\n",
    "        return centroids\n",
    "    def _assign_labels_step2(self, X):\n",
    "        distances = np.sqrt(((X - self.centroids[:, np.newaxis])**2).sum(axis=2))\n",
    "        labels = np.argmin(distances, axis=0)\n",
    "        return labels\n",
    "    def _update_centroids_step3(self, X):\n",
    "        new_centroids = np.array([X[self.labels == i].mean(axis=0) for i in range(self.n_clusters)])\n",
    "        return new_centroids\n",
    "kmeans =MyKMeans(n_clusters=5)\n",
    "kmeans.fit(X)\n",
    "Y=kmeans.labels\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJLrp9vhisX5"
   },
   "source": [
    "a)When using k=5 clusters, give a few examples of the documents assigned to each cluster, and the top 5 tokens with the highest magnitude in the corresponding centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXOnzztzoMKl"
   },
   "outputs": [],
   "source": [
    "# Loop over each cluster\n",
    "kmeans = MyKMeans(n_clusters=5, max_iter=100)\n",
    "labels, centroids = kmeans.fit(X)\n",
    "val_list = list(vectorizer.vocabulary_.values())\n",
    "key_list = list(vectorizer.vocabulary_.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3wZlaU7sSVzF",
    "outputId": "42b42319-449f-4e9a-b786-58ce9b2c06c9"
   },
   "outputs": [],
   "source": [
    "for i in range(kmeans.n_clusters):\n",
    "    # Find documents assigned to cluster i\n",
    "    cluster_docs = X[labels == i]\n",
    "    \n",
    "    # Compute top 5 features (tokens) with highest magnitude in centroid i\n",
    "    centroid = centroids[i]\n",
    "    feature_magnitudes = [(j, centroid[j]) for j in range(len(centroid))]\n",
    "    top_features = [key_list[val_list.index(feature)] for feature, _ in sorted(feature_magnitudes, key=lambda x: abs(x[1]), reverse=True)[:5]]\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Cluster {i}: {len(cluster_docs)} documents\")\n",
    "    print(f\"Top 5 features with highest magnitude in centroid: {top_features}\")\n",
    "    print(\"Examples:\")\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    a=new_df['review'][labels == i][:5]\n",
    "    print(a)\n",
    "    print(\"************************************************************************************************\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91kM6pt9i2zZ"
   },
   "source": [
    "**(c) Construct a confusion matrix between the k=5 clusters and your target labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "zAQdM-pWJ76r",
    "outputId": "1e5c1f80-4efb-4d5a-9d3c-5ed4a9f5a0a1"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Construct a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#map the lap=bel to respective numbers\n",
    "label_map = {\"positive\": 2, \"neutral\": 1, \"negative\": 0}\n",
    "true_labels = [label_map[label] for label in label_list]\n",
    "cm = confusion_matrix(true_labels, labels)\n",
    "\n",
    "# Plot confusion matrix as heatmap\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.savefig(\"confusion_matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRheYH7e9eiQ"
   },
   "source": [
    "### **Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNwuDmF09jY8"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PeA4STEZc2aq"
   },
   "outputs": [],
   "source": [
    "# Create metrics list\n",
    "\n",
    "Accuracy=[\"Accuracy\"]\n",
    "Precision=[\"Precision\"]\n",
    "Recall=[\"Recall\"]\n",
    "F1_Score=[\"F1 score\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcOwjjaYD9TL"
   },
   "source": [
    "**dummy classifier with most frequent stratergy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "7ZBOg4zKCrs8",
    "outputId": "8d7eeb88-8adc-4d15-bb78-f629442c738e"
   },
   "outputs": [],
   "source": [
    "## dummy classifier with most frequent stratergy\n",
    "\n",
    "dummy_clf_mst_frequent= DummyClassifier(strategy=\"most_frequent\")#ask this question\n",
    "dummy_clf_mst_frequent.fit(texts_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JHT_FwOS_PzD",
    "outputId": "e8e3abc9-eb61-496e-d0c3-58f4873c14dd"
   },
   "outputs": [],
   "source": [
    "labels_predicted_most_frequent=dummy_clf_mst_frequent.predict(texts_val)\n",
    "labels_predicted_most_frequent_train=dummy_clf_mst_frequent.predict(texts_train)\n",
    "\n",
    "accuracy = accuracy_score(labels_val, labels_predicted_most_frequent)\n",
    "accuracy_train = accuracy_score(labels_train, labels_predicted_most_frequent_train)\n",
    "\n",
    "print(f\"{accuracy=:.3f}\")\n",
    "Accuracy.append([accuracy_train.round(3),accuracy.round(3)])\n",
    "\n",
    "precision = precision_score(labels_val, labels_predicted_most_frequent,average=\"macro\")\n",
    "precision_train = precision_score(labels_train, labels_predicted_most_frequent_train,average=\"macro\")\n",
    "\n",
    "print(f\"{precision=:.3f}\")\n",
    "Precision.append([precision_train.round(3),precision.round(3)])\n",
    "\n",
    "recall = recall_score(labels_val, labels_predicted_most_frequent,average=\"macro\")\n",
    "recall_train = recall_score(labels_train, labels_predicted_most_frequent_train,average=\"macro\")\n",
    "\n",
    "print(f\"{recall=:.3f}\")\n",
    "Recall.append([recall_train.round(3),recall.round(3)])\n",
    "\n",
    "f1_mostfrequent= f1_score(labels_val, labels_predicted_most_frequent,average=\"macro\")\n",
    "f1_mostfrequent_train= f1_score(labels_train, labels_predicted_most_frequent_train,average=\"macro\")\n",
    "\n",
    "print(f\"{f1_mostfrequent=:.3f}\")\n",
    "F1_Score.append([f1_mostfrequent_train.round(3),f1_mostfrequent.round(3)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "uEYQe5lhIWnt",
    "outputId": "bcfb6d4f-45d9-4379-d500-8c911d803c0f"
   },
   "outputs": [],
   "source": [
    "# bar chart graph with the F1 score for each class most frequent\n",
    "f1_scores_each_class_mostfrequent = {\n",
    "    'positive': f1_score(labels_val, labels_predicted_most_frequent, average='macro', labels=['positive']),\n",
    "    'neutral': f1_score(labels_val, labels_predicted_most_frequent, average='macro', labels=['neutral']),\n",
    "    'negative': f1_score(labels_val, labels_predicted_most_frequent, average='macro', labels=['negative'])\n",
    "}\n",
    "plt.bar(f1_scores_each_class_mostfrequent.keys(), f1_scores_each_class_mostfrequent.values())\n",
    "plt.title(\"F1 Score for Each Class on validation dataset\")\n",
    "plt.xlabel(\"Class (most frequent)\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "y0IAJ4E-EBej",
    "outputId": "30d5a522-cb4e-45df-a57a-806c049ca507"
   },
   "outputs": [],
   "source": [
    "## dummy classifier with most frequent stratergy\n",
    "dummy_clf_stratified = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf_stratified.fit(texts_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQyAH1NPEjbt",
    "outputId": "d1a89ea9-a85b-43d2-a79f-2495e379e2e7"
   },
   "outputs": [],
   "source": [
    "labels_predicted_stratified=dummy_clf_stratified.predict(texts_val)\n",
    "labels_predicted_stratified_train=dummy_clf_stratified.predict(texts_train)\n",
    "\n",
    "accuracy = accuracy_score(labels_val, labels_predicted_stratified)\n",
    "accuracy_train = accuracy_score(labels_train, labels_predicted_stratified_train)\n",
    "\n",
    "print(f\"{accuracy=:.3f}\")\n",
    "Accuracy.append([accuracy_train.round(3),accuracy.round(3)])\n",
    "\n",
    "precision = precision_score(labels_val, labels_predicted_stratified,average=\"macro\")\n",
    "precision_train = precision_score(labels_train, labels_predicted_stratified_train,average=\"macro\")\n",
    "\n",
    "print(f\"{precision=:.3f}\")\n",
    "Precision.append([precision_train.round(3),precision.round(3)])\n",
    "\n",
    "recall = recall_score(labels_val, labels_predicted_stratified,average=\"macro\")\n",
    "recall_train = recall_score(labels_train, labels_predicted_stratified_train,average=\"macro\")\n",
    "\n",
    "print(f\"{recall=:.3f}\")\n",
    "Recall.append([recall_train.round(3),recall.round(3)])\n",
    "\n",
    "\n",
    "f1_stratified = f1_score(labels_val, labels_predicted_stratified,average=\"macro\")\n",
    "f1_stratified_train= f1_score(labels_train, labels_predicted_stratified_train,average=\"macro\")\n",
    "\n",
    "print(f\"{f1_stratified=:.3f}\")\n",
    "F1_Score.append([f1_stratified_train.round(3),f1_stratified.round(3)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "L4hBDj9pLswk",
    "outputId": "12efe14c-8614-4779-ec6b-47b21dfaf8d5"
   },
   "outputs": [],
   "source": [
    "## bar chart graph with the F1 score for each class stratified\n",
    "f1_scores_each_class_strtified = {\n",
    "    'positive': f1_score(labels_val, labels_predicted_stratified, average='macro', labels=['positive']),\n",
    "    'neutral': f1_score(labels_val, labels_predicted_stratified, average='macro', labels=['neutral']),\n",
    "    'negative': f1_score(labels_val, labels_predicted_stratified, average='macro', labels=['negative'])\n",
    "}\n",
    "plt.bar(f1_scores_each_class_strtified.keys(), f1_scores_each_class_strtified.values())\n",
    "plt.title(\"F1 Score for Each Class on validation dataset\")\n",
    "plt.xlabel(\"Class (stratified)\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0-dtKWAFVY1",
    "outputId": "27adc71f-37db-429a-b509-928cad206cfd"
   },
   "outputs": [],
   "source": [
    "# logistic regression using one-hot vectorization\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_onehot = CountVectorizer(binary=True)\n",
    "\n",
    "X_train_onehot = vectorizer.fit_transform(texts_train)\n",
    "X_val_onehot = vectorizer.transform(texts_val)\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train_onehot,labels_train)\n",
    "\n",
    "labels_predicted_one_hot = clf.predict(X_val_onehot)\n",
    "labels_predicted_one_hot_train = clf.predict(X_train_onehot)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(labels_val, labels_predicted_one_hot)\n",
    "accuracy_train = accuracy_score(labels_train, labels_predicted_one_hot_train)\n",
    "\n",
    "print(f\"{accuracy=:.3f}\")\n",
    "Accuracy.append([accuracy_train.round(3),accuracy.round(3)])\n",
    "\n",
    "\n",
    "precision = precision_score(labels_val, labels_predicted_one_hot,average=\"macro\")\n",
    "precision_train = precision_score(labels_train, labels_predicted_one_hot_train,average=\"macro\")\n",
    "\n",
    "print(f\"{precision=:.3f}\")\n",
    "Precision.append([precision_train.round(3),precision.round(3)])\n",
    "\n",
    "\n",
    "recall = recall_score(labels_val, labels_predicted_one_hot,average=\"macro\")\n",
    "recall_train = recall_score(labels_train, labels_predicted_one_hot_train,average=\"macro\")\n",
    "\n",
    "print(f\"{recall=:.3f}\")\n",
    "Recall.append([recall_train.round(3),recall.round(3)])\n",
    "\n",
    "\n",
    "f1_onehot = f1_score(labels_val, labels_predicted_one_hot,average=\"macro\")\n",
    "f1_onehot_train= f1_score(labels_train, labels_predicted_one_hot_train,average=\"macro\")\n",
    "\n",
    "print(f\"{f1_onehot=:.3f}\")\n",
    "F1_Score.append([f1_onehot_train.round(3),f1_onehot.round(3)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "a4tkY6YUMmxu",
    "outputId": "670b3ed4-4e4e-493b-8e7f-34b4262bc226"
   },
   "outputs": [],
   "source": [
    "## bar chart graph with the F1 score for each class onehot\n",
    "f1_scores_each_class_onehot = {\n",
    "    'positive': f1_score(labels_val, labels_predicted_one_hot, average='macro', labels=['positive']),\n",
    "    'neutral': f1_score(labels_val, labels_predicted_one_hot, average='macro', labels=['neutral']),\n",
    "    'negative': f1_score(labels_val, labels_predicted_one_hot, average='macro', labels=['negative'])\n",
    "}\n",
    "plt.bar(f1_scores_each_class_onehot.keys(), f1_scores_each_class_onehot.values())\n",
    "plt.title(\"F1 Score for Each Class on validation dataset\")\n",
    "plt.xlabel(\"Class (logistic_onehot)\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jDn7eviuTuor",
    "outputId": "fcce6536-af37-4d41-89a1-2cb4d62c502b"
   },
   "outputs": [],
   "source": [
    "##LogisticRegression with TF_IDF vectorization\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_tftdf = vectorizer_tfidf.fit_transform(texts_train)\n",
    "\n",
    "X_val_tfidf = vectorizer_tfidf.transform(texts_val)\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train_tftdf,labels_train)\n",
    "\n",
    "labels_predicted_TFIDF = clf.predict(X_val_tfidf)\n",
    "labels_predicted_TFIDF_train = clf.predict(X_train_tftdf)\n",
    "\n",
    "accuracy = accuracy_score(labels_val, labels_predicted_TFIDF)\n",
    "accuracy_train = accuracy_score(labels_train, labels_predicted_TFIDF_train)\n",
    "\n",
    "print(f\"{accuracy=:.3f}\")\n",
    "Accuracy.append([accuracy_train.round(3),accuracy.round(3)])\n",
    "\n",
    "precision = precision_score(labels_val, labels_predicted_TFIDF,average=\"macro\")\n",
    "precision_train = precision_score(labels_train, labels_predicted_TFIDF_train,average=\"macro\")\n",
    "\n",
    "print(f\"{precision=:.3f}\")\n",
    "Precision.append([precision_train.round(3),precision.round(3)])\n",
    "\n",
    "\n",
    "recall = recall_score(labels_val, labels_predicted_TFIDF,average=\"macro\")\n",
    "recall_train = recall_score(labels_train, labels_predicted_TFIDF_train,average=\"macro\")\n",
    "\n",
    "print(f\"{recall=:.3f}\")\n",
    "Recall.append([recall_train.round(3),recall.round(3)])\n",
    "\n",
    "\n",
    "f1_logistic_tfidf= f1_score(labels_val, labels_predicted_TFIDF,average=\"macro\")\n",
    "f1_logistic_tfidf_train= f1_score(labels_train, labels_predicted_TFIDF_train,average=\"macro\")\n",
    "\n",
    "print(f\"{f1_logistic_tfidf=:.3f}\")\n",
    "F1_Score.append([f1_logistic_tfidf_train.round(3),f1_logistic_tfidf.round(3)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "bgemwpQiPRsy",
    "outputId": "de6d9107-d61b-48ea-e9b6-0cfb3d98cd56"
   },
   "outputs": [],
   "source": [
    "f1_scores_each_class_logiIFIDF = {\n",
    "    'positive': f1_score(labels_val, labels_predicted_TFIDF, average='macro', labels=['positive']),\n",
    "    'neutral': f1_score(labels_val, labels_predicted_TFIDF, average='macro', labels=['neutral']),\n",
    "    'negative': f1_score(labels_val, labels_predicted_TFIDF, average='macro', labels=['negative'])\n",
    "}\n",
    "\n",
    "plt.bar(f1_scores_each_class_logiIFIDF.keys(), f1_scores_each_class_logiIFIDF.values(), color='green')\n",
    "plt.title(\"F1 Score for Each Class on validation dataset\")\n",
    "plt.xlabel(\"Class (logistic TFIDF)\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gEjtGgoiURZ",
    "outputId": "4097009c-1ca3-4d6c-d932-8afdaec3b27b"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "### svc with one-hot vectorization\n",
    "\n",
    "clf = SVC(random_state=42)\n",
    "clf.fit(X_train_onehot,labels_train)\n",
    "\n",
    "labels_predicted_svc = clf.predict(X_val_onehot)\n",
    "labels_predicted_svc_train = clf.predict(X_train_onehot)\n",
    "\n",
    "accuracy = accuracy_score(labels_val, labels_predicted_svc)\n",
    "accuracy_train = accuracy_score(labels_train, labels_predicted_svc_train)\n",
    "\n",
    "print(f\"{accuracy=:.3f}\")\n",
    "Accuracy.append([accuracy_train.round(3),accuracy.round(3)])\n",
    "\n",
    "\n",
    "precision = precision_score(labels_val, labels_predicted_svc,average=\"macro\")\n",
    "precision_train = precision_score(labels_train, labels_predicted_svc_train,average=\"macro\")\n",
    "\n",
    "print(f\"{precision=:.3f}\")\n",
    "Precision.append([precision_train.round(3),precision.round(3)])\n",
    "\n",
    "\n",
    "recall = recall_score(labels_val, labels_predicted_svc,average=\"macro\")\n",
    "recall_train = recall_score(labels_train, labels_predicted_svc_train,average=\"macro\")\n",
    "\n",
    "print(f\"{recall=:.3f}\")\n",
    "Recall.append([recall_train.round(3),recall.round(3)])\n",
    "\n",
    "\n",
    "f1_svc = f1_score(labels_val, labels_predicted_svc,average=\"macro\")\n",
    "f1_svc_train= f1_score(labels_train, labels_predicted_svc_train,average=\"macro\")\n",
    "\n",
    "print(f\"{f1_svc=:.3f}\")\n",
    "F1_Score.append([f1_svc_train.round(3),f1_svc.round(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "ezbzheKwvWHX",
    "outputId": "77636077-5cd4-4e49-ced9-279bec23afe6"
   },
   "outputs": [],
   "source": [
    "f1_scores_each_class_svc = {\n",
    "    'positive': f1_score(labels_val, labels_predicted_svc, average='macro', labels=['positive']),\n",
    "    'neutral': f1_score(labels_val, labels_predicted_svc, average='macro', labels=['neutral']),\n",
    "    'negative': f1_score(labels_val, labels_predicted_svc, average='macro', labels=['negative'])\n",
    "}\n",
    "plt.bar(f1_scores_each_class_svc.keys(), f1_scores_each_class_svc.values())\n",
    "plt.title(\"F1 Score for Each Class on validation dataset\")\n",
    "plt.xlabel(\"Class (svc_one_hot)\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBgluNb0NvaO",
    "outputId": "dd4eb2d8-2724-4b2f-c4db-ed156e68d5e8"
   },
   "outputs": [],
   "source": [
    "table_data = [[\"metrics\", \"most frequent [train,val]\", \"most stratified [train,val]\", \"logistic one hot [train,val]\", \"logistic tfidf [train,val]\", \"svc onehot [train,val]\",\"my own classifier_knn\"],\n",
    "              Accuracy,\n",
    "              Precision,\n",
    "              Recall,F1_Score]\n",
    "tablefmt = \"fancy_grid\"\n",
    "headers = [\"\\033[34m{}\\033[0m\".format(header) for header in table_data[0]]\n",
    "table_data = [headers] + table_data[1:]\n",
    "colored_data = [[f\"\\033[32m{col}\\033[0m\" if isinstance(col, int) else col for col in row] for row in table_data]\n",
    "print(tabulate(colored_data, headers=\"firstrow\", tablefmt=tablefmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkaMFvm-xcxC"
   },
   "source": [
    "**classifier b**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2Ygx85MwRf_"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "axQ0-YJExjR1",
    "outputId": "db163874-5cbe-4a14-b1ba-9016de8e878a"
   },
   "outputs": [],
   "source": [
    "##LogisticRegression with TF_IDF vectorization\n",
    "myownclassiferlist=[]\n",
    "vectorizer_tfidf_knn = TfidfVectorizer()\n",
    "X_train_tftdf_knn = vectorizer_tfidf_knn.fit_transform(texts_train)\n",
    "\n",
    "X_val_tfidf_knn = vectorizer_tfidf_knn.transform(texts_val)\n",
    "\n",
    "\n",
    "knn =KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_tftdf_knn,labels_train)\n",
    "labels_predicted_TFIDF_knn = knn.predict(X_val_tfidf_knn)\n",
    "accuracy = accuracy_score(labels_val, labels_predicted_TFIDF_knn)\n",
    "print(f\"{accuracy=:.3f}\")\n",
    "myownclassiferlist.append(accuracy.round(3))\n",
    "\n",
    "precision = precision_score(labels_val, labels_predicted_TFIDF_knn,average=\"macro\")\n",
    "print(f\"{precision=:.3f}\")\n",
    "myownclassiferlist.append(precision.round(3))\n",
    "\n",
    "recall = recall_score(labels_val, labels_predicted_TFIDF_knn,average=\"macro\")\n",
    "print(f\"{recall=:.3f}\")\n",
    "myownclassiferlist.append(recall.round(3))\n",
    "\n",
    "f1_logistic_tfidf_knn= f1_score(labels_val, labels_predicted_TFIDF_knn,average=\"macro\")\n",
    "print(f\"{f1_logistic_tfidf_knn=:.3f}\")\n",
    "myownclassiferlist.append(f1_logistic_tfidf_knn.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AeRlrTPSMGLQ"
   },
   "outputs": [],
   "source": [
    "accuracy_knn = [Accuracy[i][1] for i in range(1,6)]\n",
    "precision_knn = [Precision[i][1] for i in range(1,6)]\n",
    "recall_knn = [Recall[i][1] for i in range(1,6)]\n",
    "f1_score_knn = [F1_Score[i][1] for i in range(1,6)]\n",
    "accuracy_knn=[\"Accuracy\"]+accuracy_knn+[myownclassiferlist[0]]\n",
    "precision_knn=[\"Precision\"]+precision_knn+[myownclassiferlist[1]]\n",
    "recall_knn=[\"Recall\"]+recall_knn+[myownclassiferlist[2]]\n",
    "f1_score_knn=[\"F1 score\"]+f1_score_knn+[myownclassiferlist[3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IrmH9e5qPOok",
    "outputId": "6b160f87-70b4-441e-8bb7-3dcddbfc48d0"
   },
   "outputs": [],
   "source": [
    "table_data = [[\"metrics\", \"most frequent\", \"most stratified \", \"logistic one hot\", \"logistic tfidf\", \"svc onehot \",\"ownclassifier_knn_TFIDF\"],\n",
    "              accuracy_knn,\n",
    "              precision_knn,\n",
    "              recall_knn,f1_score_knn]\n",
    "tablefmt = \"fancy_grid\"\n",
    "headers = [\"\\033[34m{}\\033[0m\".format(header) for header in table_data[0]]\n",
    "table_data = [headers] + table_data[1:]\n",
    "colored_data = [[f\"\\033[32m{col}\\033[0m\" if isinstance(col, int) else col for col in row] for row in table_data]\n",
    "print(tabulate(colored_data, headers=\"firstrow\", tablefmt=tablefmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "6Z3IIgIH0I5o",
    "outputId": "ffc8ddce-07ac-4fb4-e850-b911406b14b7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = ['Dummy_most_frequent', 'Dummy_strtified', 'logistic_onehot','logistic_TFIDF','svc_onehot','KNN_OwnClassifier']\n",
    "sizes = [0.201, 0.341, 0.787,0.787,0.753,0.457]\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "ax.set_title('F1 score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrzOWEiB7x_j"
   },
   "source": [
    "# **tuning**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSS_BFDV75_T"
   },
   "outputs": [],
   "source": [
    "Accuracy_tuninglist=[\"Accuracy\",accuracy_knn[4]]\n",
    "Precision_tuninglist=[\"Precision\",precision_knn[4]]\n",
    "Recall_tuninglist=[\"Recall\",recall_knn[4]]\n",
    "F1_score_tuninglist=[\"F1 score\",f1_score_knn[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szMJ-Toj4Bkt",
    "outputId": "a0cf6ccb-c6f7-40c1-e2b9-6d3364478440"
   },
   "outputs": [],
   "source": [
    "##LogisticRegression with TF_IDF vectorization tuning for best performance\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "param_grid = {'C': [1,2,3,4,5,6], 'max_features': [len(val_list)],'min_df':[1,2,3,4,5,6,7,8,9],'sublinear_tf':[False,True]}\n",
    "best_params, best_f1 = None, 0\n",
    "best_accuracy=0\n",
    "best_recall=0\n",
    "best_precision=0\n",
    "for params in ParameterGrid(param_grid):\n",
    "    vectorizer = TfidfVectorizer(min_df=params['min_df'],sublinear_tf=params['sublinear_tf'],max_features=params['max_features'])\n",
    "    X_train = vectorizer.fit_transform(texts_train)\n",
    "    X_val = vectorizer.transform(texts_val)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=42, C=params['C'])\n",
    "    clf.fit(X_train,labels_train)\n",
    "    \n",
    "    labels_predicted = clf.predict(X_val)\n",
    "    \n",
    "    f1 = f1_score(labels_val, labels_predicted,average=\"macro\")\n",
    "    accuracy = accuracy_score(labels_val, labels_predicted_TFIDF)\n",
    "    precision = precision_score(labels_val, labels_predicted_TFIDF,average=\"macro\")\n",
    "    recall = recall_score(labels_val, labels_predicted_TFIDF,average=\"macro\")\n",
    "\n",
    "    print(f\"  Evaluating {params=} {accuracy=:.3f}\")\n",
    "    print(f\"  Evaluating {params=} {precision=:.3f}\")\n",
    "    print(f\"  Evaluating {params=} {recall=:.3f}\")\n",
    "    print(f\"  Evaluating {params=} {f1=:.3f}\")\n",
    "\n",
    "    if f1 > best_f1 :\n",
    "        best_params = params\n",
    "        best_f1 = f1\n",
    "       \n",
    "    if accuracy>best_accuracy:\n",
    "      best_params = params\n",
    "      best_accuracy=accuracy\n",
    "\n",
    "    if precision>best_precision:\n",
    "      best_params = params\n",
    "      best_precision=precision\n",
    "\n",
    "    if recall>best_recall:\n",
    "      best_params = params\n",
    "      best_recall=recall\n",
    "\n",
    "      \n",
    "print(f\"{best_params=}\")\n",
    "print(f\"{best_f1=:.3f}\")\n",
    "print(f\"{best_accuracy=:.3f}\")\n",
    "print(f\"{best_precision=:.3f}\")\n",
    "print(f\"{best_recall=:.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dy0e9Aft8Dfc",
    "outputId": "c0cd8690-d63c-4ba9-c521-101578376657"
   },
   "outputs": [],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer(min_df=4,sublinear_tf=False,max_features=1705)\n",
    "\n",
    "X_train_tftdf_tuning = vectorizer_tfidf.fit_transform(texts_train)\n",
    "X_val_tfidf_tuning = vectorizer_tfidf.transform(texts_val)\n",
    "\n",
    "clf = LogisticRegression(random_state=42,C=2)\n",
    "clf.fit(X_train_tftdf_tuning,labels_train)\n",
    "labels_predicted_TFIDF = clf.predict(X_val_tfidf_tuning)\n",
    "accuracy = accuracy_score(labels_val, labels_predicted_TFIDF)\n",
    "print(f\"{accuracy=:.3f}\")\n",
    "Accuracy_tuninglist.append(accuracy.round(3))\n",
    "\n",
    "precision = precision_score(labels_val, labels_predicted_TFIDF,average=\"macro\")\n",
    "print(f\"{precision=:.3f}\")\n",
    "Precision_tuninglist.append(precision.round(3))\n",
    "\n",
    "recall = recall_score(labels_val, labels_predicted_TFIDF,average=\"macro\")\n",
    "print(f\"{recall=:.3f}\")\n",
    "Recall_tuninglist.append(recall.round(3))\n",
    "\n",
    "f1_logistic_tfidf_tuning= f1_score(labels_val, labels_predicted_TFIDF,average=\"macro\")\n",
    "print(f\"{f1_logistic_tfidf_tuning=:.3f}\")\n",
    "F1_score_tuninglist.append(f1_logistic_tfidf_tuning.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQpgOs0qnC7m",
    "outputId": "766c7bac-f678-4f86-8a9e-71990189ea6e"
   },
   "outputs": [],
   "source": [
    "table_data = [[\"metrics\",\"logistic_TFIDF\",\"After Tuning\"],\n",
    "              Accuracy_tuninglist,\n",
    "              Precision_tuninglist,\n",
    "              Recall_tuninglist,F1_score_tuninglist]\n",
    "tablefmt = \"fancy_grid\"\n",
    "headers = [\"\\033[34m{}\\033[0m\".format(header) for header in table_data[0]]\n",
    "table_data = [headers] + table_data[1:]\n",
    "colored_data = [[f\"\\033[32m{col}\\033[0m\" if isinstance(col, int) else col for col in row] for row in table_data]\n",
    "print(tabulate(colored_data, headers=\"firstrow\", tablefmt=tablefmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6o5LWaDEe_e"
   },
   "source": [
    "### **Q5 BERT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E6YO4fht2jE"
   },
   "source": [
    "### **a feature extraction using transformer pipepline using roberta as the base model and training using logisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyh7jWAzEmhO",
    "outputId": "d26c116c-a67a-4297-c432-ced990dbda38"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217,
     "referenced_widgets": [
      "ab8f28ae56cf4a858537708aed09d382",
      "27a9e2431d91428188fb7d32e25c817a",
      "6972c06866574b2880d5a3c51d929d1b",
      "243c4be7ab2a495aa00726e9ebb7cf5a",
      "45936f264bd947eba1db933121fe3efe",
      "821c410528594939bc11265fd71d5121",
      "66bacf62d08c431ba2fffc54747957c7",
      "8f3faa1b3517437b924ca2d7faf18a40",
      "6bc02e3f223d49ddbdd107d3daf746e9",
      "66901736af3d4b858b080e6e794f9c6f",
      "b6127ed2183d4d4789d11266aa9dba64",
      "d9ac8300ae564bb39cc25481d84c98d1",
      "28ff70e10711416b9e7594401b4ee054",
      "dff20232564c4f70ba4573f5cfd4ad84",
      "7bd9eca983bc47df8b9bbc2ad1717204",
      "0e81645e0dc44cea8eb648a4969e338c",
      "05428a3c7fe2460d9246517a79c3742d",
      "d7989ed309794e1d8dcc42dcd8adc3de",
      "f81088b82c6041c79d881878f6f39433",
      "b24e506d2aff46ecaa57407538e73b0e",
      "c14cfe51e3054b5394ca2192b482851f",
      "d478cf05fe6446e6a0d33a8cb23d935d",
      "1a46dda2af8e4c68a2afe59a74118341",
      "f65d41b0d69649c195791b4d46863ba0",
      "739cef68ce7b46549ae1dbe911a7dd51",
      "384d765d2cf34b81a7dee8f27a49f946",
      "4ab73ef957a34b53833af003df76ea74",
      "95280dc9ad334e7a8f5c282eeb84b9d6",
      "c924b49b837a44a6a996d57840c84775",
      "9c28133e08cd4bb5b952eb88a2c6b31f",
      "e9667ba36ba6490a99f5fe86770ec214",
      "ade3124ca28941bd91a29e6151e769c2",
      "4cb7faee7c804191873e3d78cb6d95d2",
      "9b43370177224bd8a70dcc485a3acf18",
      "29803e8792a24c9da3ec901fd60e931a",
      "ab79a61ddbb3444b9ab14b0635e4a8bc",
      "e8554af7aecb4c47976f6eaaf331f1e6",
      "97d476d99fc54d67a928d9d766141db9",
      "a9abd018537545f086cfb0b1ca9ec737",
      "a14a913b827a425e8a97cfa03ba86d82",
      "857728fe2ff54e1bbfe5a48ee73e02d5",
      "1f97af73d702418281b8ee21e450a16b",
      "f4cef87d3e134900b760e8a6502f984c",
      "8141c941f76a40e38daf9eb7320b850d"
     ]
    },
    "id": "N0dTBnQzE3Z9",
    "outputId": "081aefae-dc32-4175-e387-9cb1c0fa5bc3"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "# Loading the pre-trained RoBERTa model and tokenizer\n",
    "model_name = \"roberta-base\"\n",
    "model = RobertaModel.from_pretrained(model_name)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1rnqINmF_28"
   },
   "outputs": [],
   "source": [
    "# Tokenizing the text and then converting it to input IDs\n",
    "train_encodi= tokenizer(texts_train, truncation=True, padding=True)\n",
    "val_encodi = tokenizer(texts_val, truncation=True, padding=True)\n",
    "\n",
    "# Converting the labels into numbers given in the map\n",
    "label_mapping = {\"positive\": 2, \"neutral\": 1, \"negative\": 0}\n",
    "train_labels = [label_mapping[label] for label in labels_train]\n",
    "val_labels = [label_mapping[label] for label in labels_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9eeyQT7cMSO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "\n",
    "# Define the feature extraction pipeline\n",
    "feature_extraction = pipeline(\n",
    "    \"feature-extraction\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Extract the first context vector for each document for the training and validation sets\n",
    "train_context_vectors = np.array([result[0][0] for result in feature_extraction(texts_train)])\n",
    "val_context_vectors = np.array([result[0][0] for result in feature_extraction(texts_val)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "OtOpi1IvgJBp",
    "outputId": "403d829a-07c0-453e-ab86-b4cd1f7cdaed"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# using the train data , we will trian the logistic regression model\n",
    "lr = LogisticRegression(max_iter=2000,C=10)\n",
    "lr.fit(train_context_vectors,train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FK2l7smlxfA1",
    "outputId": "9cc7b9de-e954-426d-85f0-ce986dc77ea0"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions on the validation data\n",
    "val_preds = lr.predict(val_context_vectors)\n",
    "\n",
    "#calculate the scores\n",
    "Accuracy_Bert=[\"Accuracy\"]\n",
    "Precision_Bert=[\"Precision\"]\n",
    "Recall_Bert=[\"Recall\"]\n",
    "F1_score_Bert=[\"F1 score\"]\n",
    "accuracy = accuracy_score(val_labels, val_preds)\n",
    "precision = precision_score(val_labels, val_preds,average=\"macro\")\n",
    "recall = recall_score(val_labels, val_preds,average=\"macro\")\n",
    "f1 = f1_score(val_labels, val_preds,average=\"macro\")\n",
    "Accuracy_Bert.append(accuracy.round(3))\n",
    "Precision_Bert.append(precision.round(3))\n",
    "Recall_Bert.append(recall.round(3))\n",
    "F1_score_Bert.append(f1.round(3))\n",
    "\n",
    "# evaluation metrics\n",
    "table_data = [[\"metrics\",\"Feature extraction with roberta and logisticRegression\",\"trainer from hugging face\"],\n",
    "              Accuracy_Bert,\n",
    "              Precision_Bert,\n",
    "              Recall_Bert,F1_score_Bert]\n",
    "tablefmt = \"fancy_grid\"\n",
    "headers = [\"\\033[34m{}\\033[0m\".format(header) for header in table_data[0]]\n",
    "table_data = [headers] + table_data[1:]\n",
    "colored_data = [[f\"\\033[32m{col}\\033[0m\" if isinstance(col, int) else col for col in row] for row in table_data]\n",
    "print(tabulate(colored_data, headers=\"firstrow\", tablefmt=tablefmt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBjI9OAXt9o1"
   },
   "source": [
    "### **b) uisng the trainer from the hugging face library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qRI_qM8vyos_",
    "outputId": "e9357bd8-dc90-40d3-aafe-a017fb1a8363"
   },
   "outputs": [],
   "source": [
    "\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3w_GpyvuOBt"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "batch_size = 16\n",
    "epochs = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "WY0DcMYwwYmy",
    "outputId": "4c62750b-2e7f-4965-fb41-4d8d2ef88512"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, Trainer, RobertaForSequenceClassification, RobertaTokenizer, DataCollatorWithPadding\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "train_dataset = Dataset.from_dict({'input_ids': train_encodi['input_ids'], \n",
    "                                   'attention_mask': train_encodi['attention_mask'],\n",
    "                                   'labels': train_labels})\n",
    "\n",
    "validation_dataset = Dataset.from_dict({'input_ids': val_encodi['input_ids'],\n",
    "                                        'attention_mask':val_encodi['attention_mask'], \n",
    "                                   'labels': val_labels})\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bert-model\",\n",
    "    evaluation_strategy=\"epoch\", \n",
    "    learning_rate=learning_rate, \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size, \n",
    "    num_train_epochs=epochs, \n",
    "    weight_decay=0, \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=validation_dataset, \n",
    "    tokenizer=tokenizer, \n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "jk0Tin25_pq-",
    "outputId": "7a400a51-1c07-47e1-ca05-37f88c33189d"
   },
   "outputs": [],
   "source": [
    "# predicting the labels\n",
    "predictions_first, label_ids, metrics = trainer.predict(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClLScHFJAOBY"
   },
   "outputs": [],
   "source": [
    "preds_first = np.argmax(predictions_first, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3yYrSPXA1-o"
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(val_labels, preds_first)\n",
    "precision = precision_score(val_labels, preds_first,average=\"macro\")\n",
    "recall = recall_score(val_labels, preds_first,average=\"macro\")\n",
    "f1 = f1_score(val_labels, preds_first,average=\"macro\") \n",
    "Accuracy_Bert.append(accuracy.round(3))\n",
    "Precision_Bert.append(precision.round(3))\n",
    "Recall_Bert.append(recall.round(3))\n",
    "F1_score_Bert.append(f1.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TxjiEzoyA5rX",
    "outputId": "411d38e5-5084-4bfc-fd6a-7a92c6847f5e"
   },
   "outputs": [],
   "source": [
    "table_data = [[\"metrics\",\"Feature extraction and logisticRegression\",\"trainer from hugging face\"],\n",
    "              Accuracy_Bert,\n",
    "              Precision_Bert,\n",
    "              Recall_Bert,F1_score_Bert]\n",
    "tablefmt = \"fancy_grid\"\n",
    "headers = [\"\\033[34m{}\\033[0m\".format(header) for header in table_data[0]]\n",
    "table_data = [headers] + table_data[1:]\n",
    "colored_data = [[f\"\\033[32m{col}\\033[0m\" if isinstance(col, int) else col for col in row] for row in table_data]\n",
    "print(tabulate(colored_data, headers=\"firstrow\", tablefmt=tablefmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WI7v5Uweoz3"
   },
   "source": [
    "# **c) Tuning the hyperparameter of hugging face trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "7jLVC9bc6jnb",
    "outputId": "5c97fceb-bcad-47b8-a2cc-643b97e5180e"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, Trainer, RobertaForSequenceClassification, RobertaTokenizer, DataCollatorWithPadding\n",
    "\n",
    "model_1 = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)\n",
    "tokenizer_1 = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "train_dataset = Dataset.from_dict({'input_ids': train_encodi['input_ids'], \n",
    "                                   'attention_mask': train_encodi['attention_mask'],\n",
    "                                   'labels': train_labels})\n",
    "\n",
    "validation_dataset = Dataset.from_dict({'input_ids': val_encodi['input_ids'],\n",
    "                                        'attention_mask':val_encodi['attention_mask'], \n",
    "                                   'labels': val_labels})\n",
    "learning_rate = 5e-5\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "\n",
    "training_args_1 = TrainingArguments(\n",
    "    output_dir=\"bert-model\",\n",
    "    evaluation_strategy=\"epoch\", \n",
    "    learning_rate=learning_rate, \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size, \n",
    "    num_train_epochs=epochs, \n",
    "    weight_decay=0, \n",
    ")\n",
    "\n",
    "trainer_1= Trainer(\n",
    "    model=model_1, \n",
    "    args=training_args_1,\n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=validation_dataset, \n",
    "    tokenizer=tokenizer_1, \n",
    ")\n",
    "\n",
    "trainer_1.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6odMwyrs2vmA"
   },
   "source": [
    "d) comparing the context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "M9Va_rJp2Q0a",
    "outputId": "0064abd7-62e9-47bd-8e29-bd8a97626c04"
   },
   "outputs": [],
   "source": [
    "predictions_1, label_ids_1, metrics_1 = trainer_1.predict(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0qSrmNu_bK0"
   },
   "outputs": [],
   "source": [
    "preds_1= np.argmax(predictions_1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBg1yKPuAGmj"
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(val_labels, preds_1)\n",
    "precision = precision_score(val_labels, preds_1,average=\"macro\")\n",
    "recall = recall_score(val_labels, preds_1,average=\"macro\")\n",
    "f1 = f1_score(val_labels, preds_1,average=\"macro\") \n",
    "Accuracy_Bert.append(accuracy.round(3))\n",
    "Precision_Bert.append(precision.round(3))\n",
    "Recall_Bert.append(recall.round(3))\n",
    "F1_score_Bert.append(f1.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDNLpiyzAQwd",
    "outputId": "728ecfaf-2981-4d2a-cfe7-3c9f3b5625d5"
   },
   "outputs": [],
   "source": [
    "table_data = [[\"metrics\",\"Feature extraction with logisticRegression\",\"end-to-end trainer from hugging face\",\"tuning (hugging face)\"],\n",
    "              Accuracy_Bert,\n",
    "              Precision_Bert,\n",
    "              Recall_Bert,F1_score_Bert]\n",
    "tablefmt = \"fancy_grid\"\n",
    "headers = [\"\\033[34m{}\\033[0m\".format(header) for header in table_data[0]]\n",
    "table_data = [headers] + table_data[1:]\n",
    "colored_data = [[f\"\\033[32m{col}\\033[0m\" if isinstance(col, int) else col for col in row] for row in table_data]\n",
    "print(tabulate(colored_data, headers=\"firstrow\", tablefmt=tablefmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvOrojGcEn5Y"
   },
   "source": [
    "# **d) Comparing the context vector vs Trainer from hugging face before and after tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "id": "bLqgeuuhAZ3n",
    "outputId": "eb46b22c-8108-435e-866d-efb66bdc014d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = ['Feature extraction and logisticRegression', 'trainer from hugging face', 'tuning set 1 (hugging face)']\n",
    "accuracy = [0.756, 0.799, 0.744]\n",
    "precision = [0.747, 0.791, 0.728]\n",
    "recall = [0.738, 0.789, 0.727]\n",
    "f1score = [0.74, 0.785, 0.725]\n",
    "bar_width = 0.2\n",
    "r1 = np.arange(len(models))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "r3 = [x + bar_width for x in r2]\n",
    "r4 = [x + bar_width for x in r3]\n",
    "\n",
    "plt.bar(r1, accuracy, color='b', width=bar_width, edgecolor='white', label='Accuracy')\n",
    "plt.bar(r2, precision, color='g', width=bar_width, edgecolor='white', label='Precision')\n",
    "plt.bar(r3, recall, color='r', width=bar_width, edgecolor='white', label='Recall')\n",
    "plt.bar(r4, f1score, color='m', width=bar_width, edgecolor='white', label='F1 Score')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Metric Scores')\n",
    "plt.xticks([r + bar_width for r in range(len(models))], models, rotation=45, ha='right')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxekuWQ4FUBD"
   },
   "source": [
    "# **Q6-conclusion and future work**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-sdZ_0ZGLo8"
   },
   "source": [
    "**a) getting the best performing model out of Q3/Q4/Q5 and training on the train data set and test in on the testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_-fMB14FTrY",
    "outputId": "d7a7579f-59a2-4694-86c8-2b9b770cbc3b"
   },
   "outputs": [],
   "source": [
    "# lets first group all the claassifiers from the Q3/Q4/Q5 and visualize it in a tabel\n",
    "table_data = [[\"metrics\", \"most frequent\", \"most stratified \", \"logistic one hot\", \"logistic tfidf\", \"svc onehot \",\"own_knn_TFIDF\"]+[\"context vectors\",\"end-to-end-trainer\",\"tuning(huggingface_trainer)\"],\n",
    "              accuracy_knn+Accuracy_Bert[1:],\n",
    "              precision_knn+Precision_Bert[1:],\n",
    "             recall_knn+ Recall_Bert[1:],f1_score_knn+F1_score_Bert[1:]]\n",
    "tablefmt = \"fancy_grid\"\n",
    "headers = [\"\\033[34m{}\\033[0m\".format(header) for header in table_data[0]]\n",
    "table_data = [headers] + table_data[1:]\n",
    "colored_data = [[f\"\\033[32m{col}\\033[0m\" if isinstance(col, int) else col for col in row] for row in table_data]\n",
    "print(tabulate(colored_data, headers=\"firstrow\", tablefmt=tablefmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "enoye7faCVqN"
   },
   "outputs": [],
   "source": [
    "# as we can see that the best performing model is the Hugging face trainer based on RoBERTa as base\n",
    "#lets test it on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4l99erTIsNd"
   },
   "outputs": [],
   "source": [
    "label_mapping = {\"positive\": 2, \"neutral\": 1, \"negative\": 0}\n",
    "test_labels = [label_mapping[label] for label in labels_test]\n",
    "\n",
    "tests_encodings = tokenizer(texts_test, truncation=True, padding=True)\n",
    "\n",
    "testing_dataset = Dataset.from_dict({'input_ids': tests_encodings['input_ids'],\n",
    "                                        'attention_mask':tests_encodings['attention_mask'], \n",
    "                                   'labels': test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "h5egiRxoJwM_",
    "outputId": "3e9544fd-52a2-4695-bac5-84b61fd8adbb"
   },
   "outputs": [],
   "source": [
    "predictions_tests, label_ids_tests, metrics_tests = trainer.predict(testing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0rVAxp7KzcA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "preds_tests= np.argmax(predictions_tests, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BqPL0xNRLPOW"
   },
   "outputs": [],
   "source": [
    "Accuracy_final=[\"Accuracy\"]\n",
    "Precision_final=[\"Precision\"]\n",
    "Recall_final=[\"Recall\"]\n",
    "F1_score_final=[\"F1 Score\"]\n",
    "\n",
    "accuracy = accuracy_score(test_labels, preds_tests)\n",
    "precision = precision_score(test_labels, preds_tests,average=\"macro\")\n",
    "recall = recall_score(test_labels, preds_tests,average=\"macro\")\n",
    "f1 = f1_score(test_labels, preds_tests,average=\"macro\") \n",
    "\n",
    "Accuracy_final.append(accuracy.round(3))\n",
    "Precision_final.append(precision.round(3))\n",
    "Recall_final.append(recall.round(3))\n",
    "F1_score_final.append(f1.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NfzjV23ILzFe",
    "outputId": "46d964ab-0cb5-42a3-9675-f1c44948a7b0"
   },
   "outputs": [],
   "source": [
    "table_data = [[\"Metrics of Testing\",\"Best model (hugging face trainer with RoBERTa \"],\n",
    "              Accuracy_final,\n",
    "              Precision_final,\n",
    "              Recall_final,F1_score_final]\n",
    "tablefmt = \"fancy_grid\"\n",
    "headers = [\"\\033[34m{}\\033[0m\".format(header) for header in table_data[0]]\n",
    "table_data = [headers] + table_data[1:]\n",
    "colored_data = [[f\"\\033[32m{col}\\033[0m\" if isinstance(col, int) else col for col in row] for row in table_data]\n",
    "print(tabulate(colored_data, headers=\"firstrow\", tablefmt=tablefmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "wH4MGk9wPOHy",
    "outputId": "229bdb23-4fc0-4ba3-c9bc-2344fea153d1"
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reverse_label_mapping = {2: \"positive\", 1: \"neutral\", 0: \"negative\"}\n",
    "predicted_test = [reverse_label_mapping[label] for label in preds_tests]\n",
    "\n",
    "conf_matrix = confusion_matrix(labels_test, predicted_test, labels=['positive', 'negative', 'neutral'])\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['positive', 'negative', 'neutral'],\n",
    "            yticklabels=['positive', 'negative', 'neutral'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjdRxGpQjpWt"
   },
   "source": [
    "# **b) error analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrEPyMN6jm2r",
    "outputId": "950afc03-6221-45b9-9e0e-2b2c463bae0d"
   },
   "outputs": [],
   "source": [
    "# create a list of misclassified samples\n",
    "mispredicted = []\n",
    "for i in range(len(predicted_test)):\n",
    "    if predicted_test[i] != labels_test[i]:\n",
    "        mispredicted.append((i, texts_test[i], labels_test[i], predicted_test[i]))\n",
    "for i in mispredicted[:5]:\n",
    "    print(\"Index: \", i[0])\n",
    "    print(\"Text: \", i[1])\n",
    "    print(\"True label: \", i[2])\n",
    "    print(\"Predicted label: \", i[3])\n",
    "    print(\"------------\")\n",
    "#exaplaination is given in the report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k38zYa3vPMGZ"
   },
   "source": [
    "# **Rest of the questions are answered in the report . Thank you**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
